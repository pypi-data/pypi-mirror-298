# -*- coding: utf-8 -*-
"""
First version created on Wed Feb  3 10:50:54 2021
@author: Florian Ellsäßer
Licence: This program is free software: you can redistribute it and/or modify 
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program. If not, see <https://www.gnu.org/licenses/>.

This script contains all the essential methods for the Heat Magnitude Day Index 
(HMD) and the Compound Stress Index (CSI). It further contains the crop-adaption
for the Standardized Precipitation Evapotranspiration Index (SPEI) however, the 
actual SPEI code is taken from the climate_indices package. 
"""


import numpy as np
import pandas as pd
import datetime
import xarray as xr

from .spei_utils import Periodicity
from .spei_utils import Distribution
from .spei_utils import spei
#from climate_indices import indices
#from climate_indices import compute
from sklearn.linear_model import Ridge


class HeatMagnitudeDay:
    """
    This class calculates the Heat Magnitude Day HMD as described in Zampieri 
    et al, (2017). It was adapted to get the harvest dates from the phenological
    data set in order to evaluate the index in the month before the actual 
    harvest date. 
    
    Zampieri, M., Ceglar, A., Dentener, F., Toreti, A., 2017. Wheat yield loss 
    attributable to heat waves, drought and water excess at the global, national 
    and subnational scales. Environ. Res. Lett. 12, 064008. 
    https://doi.org/10.1088/1748-9326/aa723b
    """
    
    def __init__(self,coordinate_arrays, phen_data_set,
                 index_time_range, exceedence_period, exceedence_days):
        """        
           This implementation is based on Balakrishnan Solaraju-Murali's 
           implementation of the HMD3 that was originally implemented in R. 
           
           Parameters: 
                coordinate_arrays (tuple) =  tuple of three arrays. These arrays 
                                    are generated by the getCoordinates() function 
                                    from .utils and they contain the longitude, 
                                    latitude and time coordinates of the Tmax 
                                    E-OBS data
        
                phen_data_set (pandas.core.frame.DataFrame) = this contains the 
                                    dataframe of the phenological data set 
                                    
                index_time_range (int) = the time range of the index (e.g. 3 Months
                                    => 90 days). 
                
                exceedence_period (int) = time window before and after the 
                                    actual day
                                    
            Returns:
                -
        """
        
        # create and define the input parameters
        self.in_data = None
        self.coordinate_arrays = coordinate_arrays
        self.phen_data_set = phen_data_set
        self.index_time_range = index_time_range
        self.exceedence_period = exceedence_period
        self.exceedence_days = exceedence_days
        self.harvest_phase_id = 24
        
        # define the other parameters that are only used inside of the model       
        self.in_data_length = None
        self.natural_area = None
        self.harvest_dates_array = None
        self.hmd_output = None
        
        # define the threshold values and window size 
        self._T90_threshold = 90
        self._T75_threshold = 75
        self._T25_threshold = 25
        self._window_size = exceedence_period - 1
        
        # create an array for the reference data for the whole period
        self.reference_data_array = None
        self.T90_threshold_array = None
        self.T75_threshold_array = None
        self.T25_threshold_array = None
        
        # create the reference year parameters
        self.preliminary_data_start_year = None
        self.preliminary_data_end_year = None
        self.data_start_year = None
        self.data_end_year = None
        self.reference_start_year = None
        self.reference_end_year = None
        self.start_date_ref_years = None
        self.end_date_ref_years = None
        self.start_day_ref_period = None
        self.end_day_ref_period = None
        self.start_day_ref_period_index_value = None
        self.end_day_ref_period_index_value = None
        self.in_data_reference_period = None
        self.timeline_array_reference_period = None
        self.reference_period_dataframe = None
        
        # create a mutuable copy of coordinate_arrays[2] without the leap days
        self.timeline_array = coordinate_arrays[2]
        
        # create reference thresholds
        self.reference_threshold_90 = None
        self.reference_threshold_75 = None
        self.reference_threshold_25 = None
        self.exceeding_threshold_boolean = None
        self.exceeding_threshold_Tmax_values = None
        self.all_days_of_reference_years = None
        
        # create hmd_results_output
        self.hmd_results_output = None
                
    
    def getHarvestDate(self,relevant_year):
        """ 
            This method takes the according year and returns only the harvest 
            date of that year. Using the phase_id, the natural_area_group_code
            and the reference_year it gets the according harvest date and transforms 
            it to a pandas datetime object. 
            
            Parameters:
                relevant_year (int) = the year of interest
                
            Returns:
                harvest_date (pd.datetime) = datetime object of harvest date 
        """
        
        # get all the harvest dates from that natural area for a specific year
        phaseId_Date = self.phen_data_set.loc[(self.phen_data_set['reference_year']==relevant_year) &
                          (self.phen_data_set['phase_id']==self.harvest_phase_id) & 
                      (self.phen_data_set['natural_area_group_code']==self.natural_area)][['phase_id','start_date']]
        # since we are interested in only one harvest date, we are going top create a mean of it
        harvest_date = pd.to_datetime(phaseId_Date['start_date'].astype('datetime64[ns]').mean()).date()
        
        return harvest_date
    
    def getHarvestDateArray(self):
        """
            This method takes the timeline array, creates unique years from it and 
            calls the getHarvestDate function to derive the harvest dates for each 
            year in this specific natural area region. 
            
            Parameters:
                -
            Returns:
                harvest_dates_array (numpy.ndarray) = array that contains all the
                                    harvest dates as pandas datetime objects
        
        
        """
        
        #get all the unique years in the timeline_array as readable years
        all_years = np.unique((self.timeline_array.astype('datetime64[Y]').astype(int) + 1970))
        
        # create an empty numpy array with the length of 0
        harvest_dates_array = np.empty((0, 1))
        
        # for through all the unique years and get the harvest dates
        for year in all_years:
            harvest_dates_array = np.append(harvest_dates_array, 
                                            [self.getHarvestDate(year)])
            
        return harvest_dates_array 
    
    def getStartAndEndYears(self):
        """
            This method takes the timeline_array, checks that the years have at 
            least the data available to cover the moving window and defines the 
            reference year parameters. 
            
            Parameters:
                -
            Returns:
                - 
        """
        
        # create a pandas datetime array for the dates in timeline_array
        pandas_datetime = pd.DatetimeIndex(pd.DataFrame(self.timeline_array)[0].apply(pd.Timestamp))
        
        # get a preliminary start and end year first which is just the minimum / maximum year in coordinate_arrays
        preliminary_data_start_year = self.timeline_array.min().astype('datetime64[Y]').astype(int) + 1970
        preliminary_data_end_year = self.timeline_array.max().astype('datetime64[Y]').astype(int) + 1970
        
        # define the preliminary start and end year 
        self.preliminary_data_start_year = preliminary_data_start_year
        self.preliminary_data_end_year = preliminary_data_end_year
        
        # now check if that minimum year has at least enough days to apply the window 
        if len(pandas_datetime[pandas_datetime.year == preliminary_data_start_year]) >= self._window_size:
            # if it has set that year as a start year
            self.data_start_year = preliminary_data_start_year
        else:
            # if not, we have to drop the first year
            self.data_start_year = preliminary_data_start_year + 1
            
        # now we check if that maximum year has at least enough days to apply the window too
        if len(pandas_datetime[pandas_datetime.year == preliminary_data_end_year]) >= self._window_size:
            # if it has, set that as a start year
            self.data_end_year = preliminary_data_end_year
        else:
            # if not, we have to drop the first year
            self.data_end_year = preliminary_data_end_year - 1
            
        # now define the reference start and end years
        self.reference_start_year = self.data_start_year + 1
        self.reference_end_year = self.data_end_year - 1
               
    def getReferencePeriod(self):
        """
            This method creates the Tmax data reference period array. This array
            is a pandas dataframe with the columns 'time' and 'Tmax'
            
            Parameters:
                -
            Returns:
                -
        """
                
        # create a pandas datetime array for the dates in timeline_array
        pandas_datetime = pd.DatetimeIndex(pd.DataFrame(self.timeline_array)[0].apply(pd.Timestamp))
        
        # get the first day of the reference_start_year
        self.start_date_ref_years = pandas_datetime[pandas_datetime.year == self.reference_start_year].min()
        # get the last day of the reference_end_year
        self.end_date_ref_years = pandas_datetime[pandas_datetime.year == self.reference_end_year].max()
        
        # get the start day of the reference period 
        self.start_day_ref_period = self.start_date_ref_years - pd.Timedelta(days = self._window_size)
        # get the index value of exactly that date 
        self.start_day_ref_period_index_value = np.where(self.timeline_array == self.start_day_ref_period)[0][0]
        
        # get the end day of the reference period 
        self.end_day_ref_period = self.end_date_ref_years + pd.Timedelta(days = self._window_size + 1)
        # get the index value of exactly that date 
        self.end_day_ref_period_index_value = np.where(self.timeline_array == self.end_day_ref_period)[0][0]
        # now create an array with the indices to remove       
        reference_period_remove_indices = np.concatenate((np.arange(0,self.start_day_ref_period_index_value),
                                                         np.arange(self.end_day_ref_period_index_value,(len(self.timeline_array)))),
                                                         axis=0)
        # remove all the Tmax values from in_data that are indicated by reference_period_remove_indices
        self.in_data_reference_period = np.delete(self.in_data, reference_period_remove_indices)
        #do the same for a self.timeline_array
        self.timeline_array_reference_period = np.delete(self.timeline_array, reference_period_remove_indices)
        
        # now create a dataframe of both 
        self.reference_period_dataframe = pd.DataFrame({'time': self.timeline_array_reference_period,
                                                        'Tmax': self.in_data_reference_period})
            
    def getThreshold(self):
        """
            This method fills the self.threshold_arrays with reference thresholds
            for T90, T75 and T25.
            
            Parameters:
                -
            Returns:
                -
        """
        
        # create a new column in the dataframe and get the rolling average of Tmax
        self.reference_period_dataframe['T90'] = self.reference_period_dataframe['Tmax'].rolling(window=2*self._window_size).quantile(0.9)
        self.reference_period_dataframe['T75'] = self.reference_period_dataframe['Tmax'].rolling(window=2*self._window_size).quantile(0.75)
        self.reference_period_dataframe['T25'] = self.reference_period_dataframe['Tmax'].rolling(window=2*self._window_size).quantile(0.25)
        
        # now take each unique day of the year and get the threshold value 
        self.reference_threshold_90 = self.reference_period_dataframe.groupby(self.reference_period_dataframe['time'].dt.dayofyear)['T90'].mean()
        self.reference_threshold_75 = self.reference_period_dataframe.groupby(self.reference_period_dataframe['time'].dt.dayofyear)['T75'].mean()
        self.reference_threshold_25 = self.reference_period_dataframe.groupby(self.reference_period_dataframe['time'].dt.dayofyear)['T25'].mean()
                    
    def getHeatWaves(self):
        """
            This method gets the heat wave events. This basically calls the 
            getThresholdExceedance() and the getHeatMagnitudeDayResults() method 
            to do most of the work.
            
            Parameters:
                -
            Returns:
                out_f_value_list (list) = returns a list with the f_values
        """
        
        # create empty lists to receive the final results
        hmd_results_cumulated = []
        f_value_list = []
        event_years_list = []
        
        # get Tmax for the self.index_time_range
        self.Tmax_reference_period_dataframe = pd.DataFrame({'time': self.timeline_array_reference_period,
                                                        'Tmax': self.in_data_reference_period})
        
        # create some local variables
        reference_threshold_90 = self.reference_threshold_90
        reference_threshold_75 = self.reference_threshold_75
        reference_threshold_25 = self.reference_threshold_25
        
        # get all the harvest dates with a for loop -> every loop cycle is a year
        for harvest_day in self.harvest_dates_array:
            # get the harvest day of each year
            harvest_day = pd.Timestamp(harvest_day)
            # get the doy of the harvest date 
            harvest_day_doy = harvest_day.dayofyear
            # get the beginning of the index range date 
            beginning_index_range_date = pd.Timestamp(harvest_day - datetime.timedelta(days=self.index_time_range))
            # get the doy of the beginning of the index range date
            beginning_index_range_date_doy = beginning_index_range_date.dayofyear
            
            # create an mask to remove everything that is not needed        
            mask_tmax = (self.Tmax_reference_period_dataframe['time'] > beginning_index_range_date) & (self.Tmax_reference_period_dataframe['time'] <= harvest_day)
            # get Tmax in the time range of the mask
            tmax_index_time_range = self.Tmax_reference_period_dataframe.loc[mask_tmax]
                 
            # check whether data frame is empty -> if there was no harvest date in the phen data 
            if tmax_index_time_range.empty:
                pass
            else:
                # get the time range for the index 
                threshold_t90_time_range = reference_threshold_90[(beginning_index_range_date_doy-1):(harvest_day_doy-1)]
                threshold_t75_time_range = reference_threshold_75[(beginning_index_range_date_doy-1):(harvest_day_doy-1)]
                threshold_t25_time_range = reference_threshold_25[(beginning_index_range_date_doy-1):(harvest_day_doy-1)]
                # add the thresholds to the data frame tmax_index_time_range
                tmax_index_time_range = tmax_index_time_range.assign(t90=pd.Series(threshold_t90_time_range).values)
                tmax_index_time_range = tmax_index_time_range.assign(t75=pd.Series(threshold_t75_time_range).values)
                tmax_index_time_range = tmax_index_time_range.assign(t25=pd.Series(threshold_t25_time_range).values)
                            
            # get the threshold exceedance in the range of the time range
            exceedence_time_range = self.getThresholdExceedance(tmax_index_time_range)
            
            # now calculate the HMD values with getHeatMagnitudeDayResults() 
            hmd_results = self.getHeatMagnitudeDayResults(exceedence_time_range)
            # try to get all the years with an event
            try:
                event_years_list.append(int(str(hmd_results[0][0]).split('-')[0]))
            except:
                pass
            
            # create empty list to receive the values for each loop 
            sum_fvalue_list = []
            sum_HWD_list = []
                       
            # if there are no heat waves detected pass
            if hmd_results == [] or hmd_results == None:
                pass
            # else if there are heatwaves in that period
            else:
                # get the HWF heat wave frequency (number of heat waves per year)
                HWF = len(hmd_results)
                # now append the HWF to the individual lists
                # hmd_results should look like this now: [HWtime,HWD,HWI,HWind,HWindT,i30y,thwN,fvalue]
                for heat_wave_occurence in np.arange(0, HWF, 1).tolist():
                    # add all the fvalues to a list
                    sum_fvalue_list.append(hmd_results[heat_wave_occurence][-1])
                    # add all HWDs to the list
                    sum_HWD_list.append(hmd_results[heat_wave_occurence][1])
                    # add the frequency of the occurence of heat waves
                    hmd_results[heat_wave_occurence].append(HWF)
                                        
                # sum all the fvalues
                fvalue = sum(sum_fvalue_list)                    
                                
                f_value_list.append(fvalue)
            # append the loop results to the results list     
            hmd_results_cumulated.append(f_value_list) 
            
        # now check for years without an event 
        all_years_list = list(np.arange(self.data_start_year,self.data_end_year+1,1))
        # zip the data and years with event 
        in_data_tuple = list(zip(event_years_list, f_value_list))
        # now create a pd data frame with 'year' and 'f_value' as columns
        df = pd.DataFrame(in_data_tuple, columns=['year','f_value'])
        # now reindex the missing years
        df = df.set_index(['year']).reindex(all_years_list).reset_index()
        # replace np.nan with None
        df.f_value = df.f_value.fillna(0)
        # create an out list 
        out_f_value_list = list(df.f_value)
                        
        return out_f_value_list
        
        
    def getHeatMagnitudeDayResults(self,exceedence_time_range):
        """
            This method is called by the getHeatWaves() method to actually derive 
            the heat waves. 
            
            Parameters:
                exceedence_time_range (pandas.core.series.Series) = Series with
                                exceeded threshold
            Returns:
                multiple_events_list (list) = list with the multiple heat wave
                                events
                
        """
        
        '''
        document this better, factor out the whole for loop section and try to avoid the for loop 
        '''
        # check whether data frame is empty
        if exceedence_time_range.empty:
            pass
        else:
            # convert all the values to an int and create a new column
            exceedence_time_range['Consecutive'] = (exceedence_time_range['exceeded_threshold'] != 0).astype(int)
            # now sum up all consecutive exceedence events 
            exceedence_time_range['Consecutive_count'] = np.where(
                exceedence_time_range['Consecutive'].eq(1),
                exceedence_time_range.groupby(exceedence_time_range.Consecutive.ne(exceedence_time_range.Consecutive.shift()).cumsum()).cumcount() + 1,
                np.nan,
                )
            
            # create an empty list to receive all the results
            multiple_events_list = []
            
            # TODO: for the following section I kept Balas variable names, I should 
            # change that for better readability
            
            # we group by consecutive events
            for counter, heatwave_event in exceedence_time_range.groupby([(exceedence_time_range.Consecutive != exceedence_time_range.Consecutive.shift()).cumsum()]):
                # get the data frames in chunks if the threshold was exceeded
                if (heatwave_event.Consecutive != 0).any():
                    # now we loop through the individual heatwave events
                    if heatwave_event.shape[0] >= self.exceedence_days:
                        # now add a column with the duration of the heat wave
                        heatwave_event['duration'] = heatwave_event['Consecutive_count'].max()
                        # HWtime When (starting day) did the heat wave happen
                        HWtime = heatwave_event['time'].iloc[0]
                        # HWD heat wave duration 
                        HWD = heatwave_event['duration'].iloc[0]
                        # HWI heat wave intensity (sum all the Tmax -T90 exceedences)
                        HWI = sum(heatwave_event['Tmax'] - heatwave_event['t90'])
                        # create a column for the absolute exceedance
                        heatwave_event['absolute_exceedence'] = heatwave_event['Tmax'] - heatwave_event['t90']
                        # for HWind sum up the biggest 3 exceedences
                        HWind = sum(heatwave_event['absolute_exceedence'].sort_values(ascending=False)[:3])
                        # create a new column of Tmax to get sorted in the next step
                        heatwave_event['Tmax_sorted'] = heatwave_event['Tmax']
                        # HWIndT sum up the biggest 3 Tmax 
                        HWindT = sum(heatwave_event['Tmax_sorted'].sort_values(ascending=False)[:3])
                        # create a new column for the interquantile range 
                        heatwave_event['interquartile_range'] = heatwave_event['t75']-heatwave_event['t25']
                        # sum the interquantile ranges
                        i30y = sum(heatwave_event['interquartile_range'])
                        # get the normalized temperature
                        heatwave_event['normalized_temperature'] = heatwave_event['Tmax']-heatwave_event['t25']
                        # sum up the normalized temperature
                        thwN = sum(heatwave_event['normalized_temperature'])
                        # calculate the fvalue thwN/ i30y
                        heatwave_event['fvalue'] = heatwave_event['normalized_temperature'] /  heatwave_event['interquartile_range']
                        # sum up the fvalues
                        fvalue = sum(heatwave_event['fvalue'])
                        # now we add all this information to an output list 
                        single_heat_wave_event_list =  [HWtime,HWD,HWI,HWind,HWindT,i30y,thwN,fvalue]
                        # now append everything to the multiple event list
                        multiple_events_list.append(single_heat_wave_event_list)
                    else:
                        pass
                    
                else:
                    pass
            
            return multiple_events_list
     
    def getThresholdExceedance(self,tmax_index_time_range):
        """
            This method checks whether Tmax exceeds the Threshold T90 and adds
            a new column with the Tmax that exceed the Threshold or otherwise
            just puts a 0. 
            
            Parameters:
                tmax_index_time_range (pandas.core.frame.DataFrame) = Pandas data
                frame containing Tmax and thresholds
                
            Returns (pandas.core.frame.DataFrame) = same pandas dataframe as in 
                input but with an additional column for the threshold exceedences
        """
        
        if tmax_index_time_range.empty:
            pass
        else:
            # if Tmax exceeds the threshold, we store Tmax if it doesn't we store None in a new column 'exceeded_threshold     
            tmax_index_time_range['exceeded_threshold'] = np.where(tmax_index_time_range['Tmax']> tmax_index_time_range['t90'],
                                                               tmax_index_time_range['Tmax'],
                                                               0)
        
        return tmax_index_time_range
                   
    def calculateHeatMagnitudeDay(self, in_data):
        """
            This is the core method to derive the HMD. It receives the input array
            and gets the natural area and the Tmax data from it
            
            Parameters:
                in_data (numpy.ndarray) = data array that contains the Tmax data 
                and also the natural area code as the last item.
            Returns:
                self.hmd_output (numpy.ndarray) = a numpy array that contains 
                all the HMD values for each complete year of the input data
                
        """
                
        # get the total length of the input data
        in_data_length = len(in_data)
        # get the natural_area value (last in the numpy array)
        self.natural_area = in_data[in_data_length - 1]
                # remove the natural area data to have only Tmax in the numpy array
        in_data =  in_data[:-1]
        # define the incoming data
        self.in_data = in_data
             
        # get an array with the harvest dates
        self.harvest_dates_array = self.getHarvestDateArray()
        
        #get start and end dates of reference period
        self.getStartAndEndYears()
        
        # we skip empty arrays and return only a list with Nones as final_hmd_list
        if np.isnan(self.in_data).all():
            # get the total number of years included in the data set
            total_years_in_data =  self.preliminary_data_end_year - self.preliminary_data_start_year + 1
            # create a list with the length of  total_years_in_data full of Nones
            hmd_results = [None] * total_years_in_data
            
        else:
            # get reference period
            self.getReferencePeriod()
            # get the thresholds 
            self.getThreshold()
            # now get the HMD results
            hmd_results = self.getHeatWaves()
        # convert resulting lists to numpy array    
        self.hmd_output = np.asarray(hmd_results)
        # to check weather the results make sense, print them 
        print(self.hmd_output)
         
        return self.hmd_output
    
class SPEI:
    def __init__(self,in_time,phen_data_set, index_time_range, spei_type):
        """
            This is the implementation of the Standardized Precipitation Evapotranspiration
            Index (SPEI) based on Vicente-Serrano et al. (2010) and adapted to 
            phenological cycles of crops. 
            
            Vicente-Serrano, S.M., Beguería, S., López-Moreno, J.I., 2010. A 
            Multiscalar Drought Index Sensitive to Global Warming: The Standardized 
            Precipitation Evapotranspiration Index. J. Clim. 23, 1696–1718. 
            https://doi.org/10.1175/2009JCLI2909.1
             
            Parameters:
                in_time (xarray.core.dataarray.DataArray) = time dimension of input
                time array
                
                phen_data_set (pandas.core.frame.DataFrame) = Pandas data frame 
                containing all the phenological data
                
                index_time_range (int) = range of index in days (6 month -> 180)
                
                spei_type (str) = to define daily or monthly SPEI
            Returns:
                -
        """
        
        # define the object parameters        
        self.in_time = in_time
        self.phen_data_set = phen_data_set
        self.index_time_range = index_time_range
        self.spei_type = spei_type
        
        self.min_year = int(pd.DatetimeIndex(self.in_time.time.values).year.min())
        self.max_year = int(pd.DatetimeIndex(self.in_time.time.values).year.max())
        
        self.natural_area = None
        self.t_max = None
        self.t_min = None
        self.t_mean = None
        self.precip = None
        self.t_range = None
        self.evap = None
        self.index_time_range_monthly = None
        self.d_value = None
        self.harvest_phase_id = 24
        self.d_value_timestamps = None
        
        
    def getMonthlyAverages(self,in_array):
        """
            This method takes daily data and returns monthly means 
            
            Parameters:
                in_array (numpy.ndarray) = input array of Tmax, Tmin... 
                
            Returns:
                in_array_monthly_means (numpy.ndarray) = array with monthly means
        """
        
        # add a time variable
        in_array['time'] = self.in_time
        # sortby these time groups
        in_array_sorted = in_array.sortby('time')
        # get the means of these time groups
        in_array_monthly_means = in_array_sorted.resample(time='1M').mean(dim='time')
        return in_array_monthly_means
    
    def getMiddleOfMonthDOY(self,in_array):
        """
            This method gets the middle of the month DOY (day of the year)
            
            Parameters:
                in_array (numpy.ndarray) = data input array e.g. Tmean
                
            Returns:
                doy_array (numpy.ndarray) = array with mid of month doys
        """
        
        # create an empty array to receive the doys 
        doy_array = np.empty(len(in_array))
        # now lets get to the mid of the month (-14.5 days)
        mid_of_month_dates_array = in_array.time - np.timedelta64(14, 'D') - np.timedelta64(12, 'h')
        # run a for loop to get the doy from every time stamp
        for number_in_array, timestamp in enumerate(mid_of_month_dates_array):
            # get the timestamp values
            pandas_time = pd.Timestamp(timestamp.values)
            # convert to doy
            pandas_doy = pandas_time.dayofyear
            # now add this to the numpy array 
            doy_array[number_in_array] = pandas_doy
        return doy_array
    
    def getExtraterrestrialRadiation(self,doy_array):
        """
            This method calculates the extraterrestrial Radiation (it is based 
            on an R script that I got from Andrea Toreti)
            
            Parameters:
                doy_array (numpy.ndarray) = array with doys from mid month days
                
            Returns:
                extraterestrial_radiation (float) = extraterestrial radiation
            
        """
                
        # get the delta angle
        delta_angle = 0.409 * np.sin(0.0172 * doy_array - 1.39)
        # calculate the eccentricity correction factor
        dr = 1 + 0.033 * np.cos(0.0172 * doy_array)
        # calculate latitude in radians
        latitude_in_radians = self.latitude/57.2957795
        # get the hourly angle of sun rising
        hourly_angle_of_sun_rising = -np.tan(latitude_in_radians) * np.tan(delta_angle)
        # get empty omega array 
        omegas = hourly_angle_of_sun_rising
        # and fill with omegas
        omegas[(omegas.any() >= -1) and (omegas.any() <= 1)] = np.arccos(omegas[(omegas.any() >= -1) and (omegas.any() <= 1)])
        # calculate the extraterestrial_radiation MJ m-2 day-1
        extraterestrial_radiation = 37.6 * dr * (omegas * np.sin(latitude_in_radians)
                                                 * np.sin(delta_angle) + np.cos(latitude_in_radians)
                                                 * np.cos(delta_angle * np.sin(omegas))
                                                 )
        return extraterestrial_radiation
        
    def getEvapotranspiration(self):
        """
            This method calculates evapotranspiration following Hargreaves
            and Samani (1985) as described in Shahidian et al. (2012)
            
            Hargreaves, G.H., Samani, Z.A., 1985. REFERENCE CROP EVAPOTRANSPIRATION 
            FROM AMBIENT A I R TEMPERATURE 13.
            
            Shahidian, S., Serralheiro, R., Serrano, J., Teixeira, J., Haie, N., 
            Santos, F., 2012. Hargreaves and Other Reduced-Set Methods for Calculating 
            Evapotranspiration, in: Irmak, A. (Ed.), Evapotranspiration - Remote 
            Sensing and Modeling. InTech. https://doi.org/10.5772/18059
            
            Parameters:
                -
            Returns:
                -
        """
        ''' '''
        # first get the doy 
        doy_array = self.getMiddleOfMonthDOY(self.t_mean)
        # then get the extraterestrial radiation
        extraterestrial_radiation = self.getExtraterrestrialRadiation(doy_array)
        # calculate the evapotranspiration following Hargreaves and Shaidian et al. (2012)
        self.evap =0.0013 * 0.408 * extraterestrial_radiation * (self.t_mean + 17) * (self.t_range - 0.01239)**0.76
        
    def getHarvestDateArray(self):
        """
            This method derives the harvest dates for each year by looping through
            the years and calling the getHarvestDate() function
            
            Parameters:
                -
            Returns:
                harvest_dates_array (numpy.ndarray)
        """
        
        #get all the years in the data
        all_years = np.unique((self.in_time.astype('datetime64[Y]').dt.year))
        # create an empty numpy array with the length of 0
        harvest_dates_array = np.empty((0, 1))
        # for through all the unique years and get the harvest dates
        for year in all_years:
            harvest_dates_array = np.append(harvest_dates_array, 
                                            [self.getHarvestDate(year)])
            
        return harvest_dates_array 
    
    # get only the dates of the according reference year and the harvest date id
    def getHarvestDate(self,relevant_year):
        """
            This method takes the relevant year and looks up the harvest date
            in the phenological data set taking into account the natural area
            group
            
            Parameters:
                relevant_year (int) = the year of interest
            Returns:
                date (pandas.datetime) = returns pandas datetime object of the 
                harvest date
        """
        # this checks the phen data set for the reference year and the phase id
        phaseId_Date = self.phen_data_set.loc[(self.phen_data_set['reference_year']==relevant_year) &
                          (self.phen_data_set['phase_id']==self.harvest_phase_id) & 
                      (self.phen_data_set['natural_area_group_code']==self.natural_area)][['phase_id','start_date']]
        # since we are interested in only one harvest date, we are going top create a mean of it
        date = pd.to_datetime(phaseId_Date['start_date'].astype('datetime64[ns]').mean()).date()
        
        return date
    
    def getDValueSeries(self,harvest_date_array,d_value_dataframe):
        """
            This method gets the series of dvalues in the index relevant time 
            prior to the harvest month.
            
            Parameters:
                harvest_date_array (numpy.ndarray) = an array with the harvest
                dates from all the years
                
                d_value_dataframe = (pandas.core.frame.DataFrame) = pandas data
                frame with the d_values
                
            Returns:
                d_value_series_dataframe (pandas.core.frame.DataFrame) = pandas 
                data frame with the d_value Series   
        """
        # TODO: At the moment the WHOLE harvest month is considered. Which is quite 
        #       stuid if e.g. the harvest date is the 4th of October then the whole 
        #       october is still considered
        
        # create a list to get all the years and the monthly d_values
        d_value_series_list = []
        # loop through the harvest dates
        for number, harvest_date in enumerate(harvest_date_array):
            # get the harvest year and the harvest month 
            harvest_year, harvest_month  = harvest_date.year, harvest_date.month
            # now get the spei beginning month of this respective year 
            spei_begin_month = harvest_date.month - self.index_time_range_monthly
            # check if that becomes negative
            if spei_begin_month < 0:
                # print a message to raise awareness
                print('you should also consider the last year!!!')
            else:
                pass
            # create an empty list
            d_value_list = []    
            # add the year first 
            d_value_list.append(harvest_year)
            
            try:
                # for through each month
                for month in np.arange(spei_begin_month,harvest_month,1):
                    try:
                        # get the d_value
                        d_value = float(d_value_dataframe[(d_value_dataframe.year == harvest_year) 
                                                        & (d_value_dataframe.month == month)].d_value.values)
                    except:
                        pass
                    # append the d_value to the list
                    d_value_list.append(d_value)
            except:
                # create an empty dummy list
                d_value_list = [harvest_year,None,None,None,None,None,None]
            # append to master list    
            d_value_series_list.append(d_value_list)
            
        # create a list for the headers
        column_names = []
        column_names.append('year')
        # now get the rest of the column names
        for month_number in np.arange(0,self.index_time_range_monthly):
            # append them to the column list
            column_names.append(str('d_value_'+str(int(month_number))))
            
        # now create and return a dataframe
        d_value_series_dataframe = pd.DataFrame(columns=column_names, 
                                                data=d_value_series_list)    
        
        return d_value_series_dataframe
            
    def empiricalCumulativeDistributionFunction(self,in_data):
        """
            This method adds a probability distribution to the in data  
            
            Parameters:
                in_data (pandas.core.series.Series) = the sums of the d_values
            Returns:
                sort_data (numpy.ndarray) = sorted in_data
                percentiles(list) = list with percentiles for sorted in_data
        """
        # create an empty list
        percentiles = []
        # get the data length
        data_length = len(in_data)
        # sort the data
        sort_data = np.sort(in_data)
        # now get a percentile for each item in the d_value data
        for d_value_sum in np.arange(1,data_length+1):
            # get the percentiles
            percentle = d_value_sum/data_length
            # append to big list
            percentiles.append(percentle)
        
        return sort_data, percentiles 

    def getSPEIHarvestDateSeries(self,harvest_date_array,result_spei):
        """
            This method gets the SPEI values for the harvest dates and returns 
            an array with only the SPEI dates
            
            Parameters:
                harvest_date_array
                result_spei
            Returns:
                spei_series_dataframe (pandas.core.frame.DataFrame) = SPEI for 
                the harvest dates
        """
        
        # d_value time stamp is 241 long and result_spei only 240 therfore we 
        # insert a zero to first position -> check if that is actually the 
        # position that is missing
        result_spei = np.insert(result_spei,0, 0)
        # create a pandas dataframe from both d_value and d_value timestamps
        spei_dataframe = pd.DataFrame(columns = ['spei', 'spei_timestamp', 'year', 'month'])
        # now set the spei column in the data frame as result spei
        spei_dataframe.spei = result_spei
        # remove the last row of the dataframe
        spei_dataframe = spei_dataframe[:-1]
        # now define the spei_timestamps column
        spei_dataframe.spei_timestamp = self.d_value_timestamps
        # extend dataframe timestamps to year and month only 
        spei_dataframe.year = spei_dataframe.spei_timestamp.dt.year
        spei_dataframe.month = spei_dataframe.spei_timestamp.dt.month
        # create a list to get all the years and the monthly spei
        spei_series_list = []
        # loop through the harvest dates
        for number, harvest_date in enumerate(harvest_date_array):
            # get the harvest year and the harvest month 
            harvest_year, harvest_month  = harvest_date.year, harvest_date.month
            # now get the spei beginning month of this respective year 
            spei_begin_month = harvest_date.month - self.index_time_range_monthly
            # check if that becomes negative
            if spei_begin_month < 0:
                # print a warning message
                print('you should also consider the last year!!!')
            else:
                pass
            # create an empty list for the spei
            spei_list = []    
            # add the year first 
            spei_list.append(harvest_year)
            try: 
                # now run the for loop 
                for month in np.arange(spei_begin_month,harvest_month,1):
                    
                    try:
                        spei = float(spei_dataframe[(spei_dataframe.year == harvest_year) 
                                                        & (spei_dataframe.month == month)].spei.values)    
                    except:
                        pass
                    # append the spei to the spei list
                    spei_list.append(spei)
            except:
                # create an empty dummy file
                spei_list = [harvest_year,None,None,None,None,None,None]
            # append to spei series list    
            spei_series_list.append(spei_list)
        # create a list for the headers
        column_names = []
        column_names.append('year')
        # get header list
        for month_number in np.arange(0,self.index_time_range_monthly):
            # append to column header list
            column_names.append(str('spei_'+str(int(month_number))))
        # now create dataframe
        spei_series_dataframe = pd.DataFrame(columns=column_names, 
                                                data=spei_series_list)  
        return spei_series_dataframe       
            
            
    def calculateSPEI(self, in_data):
        """
            This method is the SPEI (Standardized Precipitation Evapotranspiration
            Index) main function. It returns an xarray frame in the (longitude 
            and latitude) shape of the input xarray file with the SPEI results for every year. 
            
            Parameters:
                in_data (numpy.ndarray) = data array containing natural area, 
                latitudes, precipitation, Tmean, Tmax and Trange
            Returns:
                spei_harvest_dates['spei_5'] (pandas.core.series.Series) = series 
                with SPEI value for each year
        """
        
        # get the natural_area value (last in the numpy array)
        self.natural_area = in_data[0]
        # get the latitude value (last in the numpy array)
        self.latitude = in_data[1]
        # remove the first two items
        in_data =  in_data[2:]
        # now get the t_max, t_min and precip from the in_data
        single_data_length = int(in_data.shape[0] / 4)
        # get the precip data first
        self.precip = in_data[:single_data_length]
        # convert to xarray using the self.in_time
        self.precip = xr.DataArray(data=self.precip, coords={'time':self.in_time}, 
                                   dims={'time':self.in_time}, name='precip', 
                                   attrs=None, indexes=None, fastpath=False)
        # now get the t_mean
        self.t_mean = in_data[single_data_length:single_data_length*2]
        # convert to xarray using the self.in_time
        self.t_mean = xr.DataArray(data=self.t_mean, coords={'time':self.in_time}, 
                                   dims={'time':self.in_time}, name='t_mean', 
                                   attrs=None, indexes=None, fastpath=False)
        # now get the t_min
        self.t_min = in_data[single_data_length*2:single_data_length*3]
        # convert to xarray using the self.in_time
        self.t_min = xr.DataArray(data=self.t_min, coords={'time':self.in_time}, 
                                   dims={'time':self.in_time}, name='t_min', 
                                   attrs=None, indexes=None, fastpath=False)
        # now get t_max
        self.t_max = in_data[single_data_length*3:]
        # convert to xarray using the self.in_time
        self.t_max = xr.DataArray(data=self.t_max, coords={'time':self.in_time}, 
                                   dims={'time':self.in_time}, name='t_max', 
                                   attrs=None, indexes=None, fastpath=False)
        # create the range between t_min and t_max
        self.t_range = self.t_max - self.t_min
        # convert to xarray using the self.in_time
        self.t_range = xr.DataArray(data=self.t_range, coords={'time':self.in_time}, 
                                   dims={'time':self.in_time}, name='t_range', 
                                   attrs=None, indexes=None, fastpath=False)
        # Skip empty data        
        if np.isnan(self.t_max).all():
            #print('this array is empty')
            print('Empty data...')
            # create empty array
            time = self.t_mean.time.values
            year_list =[]
            for item in time:
                year = item.astype('datetime64[Y]').astype(int) + 1970
                year_list.append(year)
            years = np.unique(year_list)
            empty_return_array = np.full(len(years),None)
            
            return empty_return_array
            
        else:
            # check if monthly or daily spei is required
            if self.spei_type == 'monthly':
                print('monthly spei selected')
                #print(self.min_year,' --- ',self.max_year)
                # convert daily input data to monthly 
                self.precip = self.getMonthlyAverages(self.precip)
                self.t_min = self.getMonthlyAverages(self.t_min)
                self.t_max = self.getMonthlyAverages(self.t_max)
                self.t_mean = self.getMonthlyAverages(self.t_mean)
                self.t_range = self.getMonthlyAverages(self.t_range)
                
                # round the days to month
                self.index_time_range_monthly = np.round(self.index_time_range/30.5)
                
            elif self.spei_type == 'daily':
                print('daily spei selected - not implemented yet')
                # TODO: add daily SPEI some day
                pass
            
            else:
                pass
            
            # get evapotranspiration 
            self.getEvapotranspiration()
            # get d value 
            self.d_value = self.precip - self.evap
            # get d_value time stamps
            self.d_value_timestamps = self.t_mean.time.values
            # create a pandas dataframe from both d_value and d_value timestamps
            d_value_dataframe = pd.DataFrame(columns = ['d_value', 'd_value_timestamp', 'year', 'month'])
            # fill the d_value column
            d_value_dataframe.d_value = self.d_value
            # fill the d_value time stamp column
            d_value_dataframe.d_value_timestamp = self.d_value_timestamps
            # extend dataframe timestamps to year and month only 
            d_value_dataframe.year = d_value_dataframe.d_value_timestamp.dt.year
            d_value_dataframe.month = d_value_dataframe.d_value_timestamp.dt.month
            # get the harvest date
            harvest_date_array = self.getHarvestDateArray()
            # get the dvalues series from the time period before the harvest date
            d_value_series_dataframe = self.getDValueSeries(harvest_date_array, d_value_dataframe)
            # sum up the d_values 
            d_value_series_dataframe['d_value_sum'] = d_value_series_dataframe.loc[:, d_value_series_dataframe.columns != 'year'].sum(axis=1)
            # make a try except for the periodicity here - this has to do with
            # the different versions of climate_indices
            # TODO: supress error messages here
            try:
                result_spei = spei(precips_mm = np.asarray(self.precip),
                pet_mm = np.asarray(self.evap),
                scale = np.array([6]),
                distribution = Distribution.gamma,
                periodicity = 'monthly',
                #periodicity = 'monthly', # this is optional depending on which version of climate_indices is present
                data_start_year = self.min_year,
                calibration_year_initial = self.min_year,
                calibration_year_final = self.max_year-1)
                
            except:
                result_spei = spei(precips_mm = np.asarray(self.precip),
                pet_mm = np.asarray(self.evap),
                scale = np.array([6]),
                distribution = Distribution.gamma,
                ###periodicity = compute.Periodicity.monthly,
                periodicity = Periodicity.monthly,
                #periodicity = 'monthly', # this is optional depending on which version of climate_indices is present
                data_start_year = self.min_year,
                calibration_year_initial = self.min_year,
                calibration_year_final = self.max_year-1)
            # now add the probability distribution
            sort_data,percentiles = self.empiricalCumulativeDistributionFunction(d_value_series_dataframe['d_value_sum'])
            # now get the spei for the harvest days 
            spei_harvest_dates = self.getSPEIHarvestDateSeries(harvest_date_array,result_spei)
            print(list(spei_harvest_dates['spei_5']))
            return spei_harvest_dates['spei_5']
                
class CompoundStressIndex:
    """
        This class calculates the Compound Stress Index as described in Zampieri 
        et al, (2017). It was adapted to get the harvest dates from the phenological
        data set in order to evaluate the index in the month before the actual 
        harvest date. 
        
        Zampieri, M., Ceglar, A., Dentener, F., Toreti, A., 2017. Wheat yield loss 
        attributable to heat waves, drought and water excess at the global, national 
        and subnational scales. Environ. Res. Lett. 12, 064008. 
        https://doi.org/10.1088/1748-9326/aa723b
    """
    def __init__(self, in_time, compare_mode=False):
        """
            This method helps to initiate the CSI object.
            
            Parameters:
                in_time (xarray.core.dataarray.DataArray) = array with all the 
                years as datetime objects
                
            Returns:
                -           
        """
        
        self.in_time = in_time
        self.compare_mode=compare_mode
        self.in_hmd = None
        self.in_spei = None
        self.in_yield = None
        self.in_yield_original = None
        self.csi = None
        self.csi_out = None
        self.a_parameter = None
        self.b_parameter = None
    
        
    def calculateCSI(self, in_data):
        """
            This method takes the input data array and splits it into its hmd, spei
            and yield components. It runs the calculation of the CSI and returns 
            an array with the yearly results.
            
            Parameters:
                in_data (xarray.core.dataarray.DataArray) = array of HMD, SPEI and
                yield productivity data. 
                 
            Returns:
                self.csi_out (numpy.ndarray) = yearly CSI results
        """
        
        # get the time as an xarray
        self.in_time = xr.DataArray(list(self.in_time.values), coords=[list(self.in_time.values)], dims=["time"])
        # get total data length and divide by three                
        self.single_data_length = int(len(in_data) / 3)
        #get hmd data 
        self.in_hmd = in_data[:self.single_data_length]
        # now get spei data
        self.in_spei = in_data[self.single_data_length:self.single_data_length*2]
        # now get the yield data
        self.in_yield = in_data[self.single_data_length*2:self.single_data_length*3]
        
        self.in_yield_original = self.in_yield
        
        # skip the empty arrays
        if np.isnan(self.in_hmd.astype('float32')).all():
            # print that the data is empty
            print('only NaN...')
            # return an empty array
            return np.array([None]*len(self.in_hmd)), np.array([None]*len(self.in_hmd)), np.array([None]*len(self.in_hmd))
        
        elif np.all((self.in_hmd.astype('float32') == 0)):
            # print that the data is empty
            print('only zeros...')
            # return an empty array
            return np.array([None]*len(self.in_hmd)), np.array([None]*len(self.in_hmd)), np.array([None]*len(self.in_hmd))
            
        else:

            # check if in-data contains NaNs and replace them with zero
            self.in_hmd = np.nan_to_num(self.in_hmd)
            self.in_hmd[self.in_hmd == None] = 0
            self.in_spei = np.nan_to_num(self.in_spei)
            self.in_spei[self.in_spei == None] = 0
            self.in_yield = np.nan_to_num(self.in_yield)
            self.in_yield[self.in_yield == None] = 0
            
            
            try:
                # standardize the HMD and the productivity
                self.in_hmd = (self.in_hmd - np.mean(self.in_hmd)) / np.std(self.in_hmd)
            
                self.in_yield = (self.in_yield - np.mean(self.in_yield)) / np.std(self.in_yield)
                # after talking with Matteo, we can also standardize the SPEI 
                self.in_spei = (self.in_spei - np.mean(self.in_spei)) / np.std(self.in_spei)

                # convert to xarray using the self.in_time
                self.in_hmd = xr.DataArray(data=self.in_hmd, coords=[self.in_time], 
                                           dims={'year':self.in_time}, name='in_hmd', 
                                           attrs=None, indexes=None, fastpath=False)
                # convert to xarray using the self.in_time
                self.in_spei = xr.DataArray(data=self.in_spei, coords=[self.in_time], 
                                           dims={'year':self.in_time}, name='in_spei', 
                                           attrs=None, indexes=None, fastpath=False)
                # convert to xarray using the self.in_time
                self.in_yield = xr.DataArray(data=self.in_yield, coords=[self.in_time], 
                                           dims={'year':self.in_time}, name='in_yield', 
                                           attrs=None, indexes=None, fastpath=False)
                # calculate the z-score for standardization
                self.in_hmd_z_score = self.calculate_z_score(self.in_hmd)
                self.in_spei_z_score = self.calculate_z_score(self.in_spei)
                self.in_yield_z_score = self.calculate_z_score(self.in_yield)
                # get ridge coefficients
                self.hmd_z_coefs = self.get_ridge_coefficients(self.in_yield_z_score,
                                       self.in_hmd_z_score)
                self.spei_z_coefs = self.get_ridge_coefficients(self.in_yield_z_score,
                                       self.in_spei_z_score)
                # create a pandas dataframe from the lists
                self.coef_data = pd.DataFrame({'hmd_z_coefs':list(self.hmd_z_coefs),
                             'spei_z_coefs':list(self.spei_z_coefs)})
                # now calculate the CGV and check for first minimum and invert the parameters
                # https://stackoverflow.com/questions/51922622/finding-first-minimum-values-python
                self.a_parameter = self.coef_data.hmd_z_coefs.expanding().min()[1] * (-1)
                self.b_parameter = self.coef_data.spei_z_coefs.expanding().min()[1] * (-1)
        
                # calculate csi as in Zampieri et al. (2017)
                try:
                    # a parameter is always resulting positive, the rest is equation 2 
                    self.csi_out = abs(self.a_parameter) * self.in_hmd + self.b_parameter * self.in_spei
                except:
                    print('calculation of CSI errored!')
                    # or return an emty array if necessary
                    self.csi_out = np.array([None] *self.in_yield.size)
                    
                if self.compare_mode == True:
                    print('compare_mode!')
                    self.csi_out = self.get_compare_mode() ## add threefold output here!!
                else:
                    pass
                print(self.csi_out.values)    
                            
                return self.csi_out, np.array([self.a_parameter]*len(self.in_hmd)), np.array([self.b_parameter]*len(self.in_hmd))
                #return np.array([None]*len(self.in_hmd)), np.array([None]*len(self.in_hmd)), np.array([None]*len(self.in_hmd))
            except: 
                return np.array([None]*len(self.in_hmd)), np.array([None]*len(self.in_hmd)), np.array([None]*len(self.in_hmd))
                pass
                
            
        
    def get_compare_mode(self):
        """This follows an idea of Matteo to make the CSI more comparable to the 
        yield"""
        
        #it is a bit cryptic what Matteo meant with a representative mean, I just
        # took the regular mean here, maybe ask again! 
        comapare_mode_CSI = (self.csi_out * np.std(self.in_yield)) + np.mean(self.in_yield_original)
        
        return comapare_mode_CSI
    
    def calculate_z_score(self, in_array):
        """
            This method calculates the z-score.
            
            Parameters:
                in_array (numpy.ndarray) = array with hmd, spei or yield data
                
            Returns:
                in_array_z_score (numpy.ndarray) = array with z-scores
        """
        
        
        try:
            # get difference to mean and divide by standard deviation 
            in_array_z_score = np.array((in_array - np.nanmean(in_array,dtype='float32'))/ (np.nanstd(in_array,dtype='float32'))).reshape(-1, 1)
        except:
            # if above operation doesn't work, return an array with ones
            in_array_z_score = np.array([[1]]*self.single_data_length)
        return in_array_z_score

    def get_ridge_coefficients(self,x_in,y_in):
        """
            This method calculates the ridge regression following the method
            described here: https://towardsdatascience.com/ridge-regression-for-better-usage-2f19b3a202db
            
            Parameters:
                x_in (numpy.ndarray) = numpy array with regression input
                y_in (numpy.ndarray) = numpy array with regression input                
                
            Returns:
                out_list (list) = list with regression coefficients
        """
        
        # imput a mean for the NaN values
        x_in = np.where(x_in == None, np.nanmean(x_in,dtype='float32'),x_in)
        y_in = np.where(y_in == None, np.nanmean(y_in,dtype='float32'),y_in)
        
        # remove the Nones and replace by zero
        x_in[x_in==None] = 0
        y_in[y_in==None] = 0
        x_in = np.nan_to_num(x_in)
        y_in = np.nan_to_num(y_in)
        
        # create an empty output list
        out_list = []
        # iterate through the lambdas
        for alpha in np.arange(0, 500, 0.1):
            # initiate the ridge regression
            ridge_reg = Ridge(alpha=alpha)
            # fit the x and y variables
            ridge_reg.fit(x_in, y_in)
            # now append coef value to the out list
            out_list.append(ridge_reg.coef_[0][0])
        return out_list